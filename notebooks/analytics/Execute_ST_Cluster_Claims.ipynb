{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02bd90-1681-4415-904f-f2c2bd08dd0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install st_dbscan\n",
    "from st_dbscan import ST_DBSCAN\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ST_Cluster import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59e5f1-9a33-47e4-9301-385ff4ad9c59",
   "metadata": {},
   "source": [
    "# Clustering Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65b06e-76c1-4e03-874f-d3399b44b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_thres_list = [0.5, 1, 2, 3, 4]\n",
    "time_thres_list = [3, 5, 7, 14, 30]\n",
    "num_thres_list = [3, 5, 7, 10]\n",
    "\n",
    "# Create a folder for temporary files\n",
    "temp_folder = \"Clusters/2025_all\"\n",
    "os.makedirs(temp_folder, exist_ok=True)\n",
    "damage_only = True\n",
    "\n",
    "save = False\n",
    "save_small=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cfb753-c02b-45d6-8832-37e5942cdfbf",
   "metadata": {},
   "source": [
    "# Claims Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e9a7e-339c-49c2-81fd-a2e14a8145d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "claims = pd.read_csv(\"../3_Failure_Modes/FimaNfipClaims_Aug2025.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f040df-b3b0-4fda-953e-411adc6c14cd",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc96c8-df3e-4a10-9401-53d01cfa16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'dateOfLoss' is NA\n",
    "claims = claims.dropna(subset=['dateOfLoss'])\n",
    "\n",
    "# Drop rows where 'latitude' or 'longitude' is NA or blank\n",
    "claims = claims.dropna(subset=['latitude', 'longitude'])\n",
    "claims = claims[(claims['latitude'] != '') & (claims['longitude'] != '')]\n",
    "\n",
    "# Remove rows where 'buildingDamageAmount' is less than 1\n",
    "if damage_only:\n",
    "    claims = claims[claims['buildingDamageAmount'] >= 1]\n",
    "\n",
    "# Preprocess 'dateOfLoss' to numeric days\n",
    "claims['dateOfLoss'] = pd.to_datetime(claims['dateOfLoss']).dt.tz_localize(None)\n",
    "origin_date = claims['dateOfLoss'].min()\n",
    "claims['daysSinceStart'] = (claims['dateOfLoss'] - origin_date).dt.days\n",
    "claims['date'] = pd.to_datetime(claims['daysSinceStart'], unit='D', origin=origin_date)\n",
    "\n",
    "# Create a unique index for each row\n",
    "claims['index'] = claims.index\n",
    "\n",
    "# Drop rows where 'countyCode' is NaN\n",
    "claims = claims.dropna(subset=['countyCode'])\n",
    "\n",
    "# Ensure that 'countyCode' is properly formatted as a 5-character string\n",
    "claims['countyCode'] = claims['countyCode'].astype(int).astype(str)\n",
    "claims['countyCode'] = claims['countyCode'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "# Define the bounds for the contiguous US\n",
    "bounds = {\n",
    "    \"min_lon\": -130,\n",
    "    \"max_lon\": -65,\n",
    "    \"min_lat\": 24,\n",
    "    \"max_lat\": 50\n",
    "}\n",
    "\n",
    "# Filter the DataFrame\n",
    "claims = claims.dropna(subset=['latitude', 'longitude']).loc[\n",
    "    (claims['longitude'] >= bounds[\"min_lon\"]) &\n",
    "    (claims['longitude'] <= bounds[\"max_lon\"]) &\n",
    "    (claims['latitude'] >= bounds[\"min_lat\"]) &\n",
    "    (claims['latitude'] <= bounds[\"max_lat\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb5925-cd5d-4ebd-bf2b-37ee7de019a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claims, sensitivities = sensitivity_analysis(claims, space_thres_list, time_thres_list, num_thres_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0995a-9f4d-45ae-8162-0accf35fd9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    # Save the sensitivity analysis\n",
    "    sensitivities.to_csv(f'{temp_folder}/cluster_sensitivities_cl.csv', index=False)\n",
    "\n",
    "    # Save the clustered claims\n",
    "    claims.to_csv(f\"{temp_folder}/clustered_claims_sensitivity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada48b6-0fab-4b2b-89ea-72b86e7c6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_small:\n",
    "    claims[['id','dateOfLoss','longitude','latitude','st_cluster_3_5_7']].to_csv(f\"{temp_folder}/clustered_claims_export.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb1cbe-b8ce-4444-995e-c8c874d2696f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

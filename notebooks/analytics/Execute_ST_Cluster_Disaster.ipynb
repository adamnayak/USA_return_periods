{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02bd90-1681-4415-904f-f2c2bd08dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install st_dbscan\n",
    "from st_dbscan import ST_DBSCAN\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.colors as mcolors\n",
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "from ST_Cluster import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59e5f1-9a33-47e4-9301-385ff4ad9c59",
   "metadata": {},
   "source": [
    "# Clustering Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65b06e-76c1-4e03-874f-d3399b44b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_thres_list = [0.5, 1, 2, 3, 4]\n",
    "time_thres_list = [1, 3, 5, 7, 14, 30]\n",
    "num_thres_list = [3, 5, 7, 10]\n",
    "\n",
    "# Create a folder for temporary files\n",
    "temp_folder = \"Clusters\"\n",
    "os.makedirs(temp_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd0993-6baa-4629-8e1d-b39288b5d096",
   "metadata": {},
   "source": [
    "# Disaster Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b73e6-617e-4cf1-afff-cefd6dce998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = pd.read_csv(\"../../final_filtered_disasters.csv\")\n",
    "\n",
    "# Ensure that 'fullFIPS' is properly formatted as a 5-character string\n",
    "disasters['fullFIPS'] = disasters['fullFIPS'].astype(int).astype(str)\n",
    "disasters['fullFIPS'] = disasters['fullFIPS'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "# Preprocess 'incidentBeginDate' to numeric days\n",
    "disasters['incidentBeginDate'] = pd.to_datetime(disasters['incidentBeginDate'])  # Ensure column is datetime type\n",
    "\n",
    "origin_date = disasters['incidentBeginDate'].min()\n",
    "disasters['daysSinceStart'] = (disasters['incidentBeginDate'] - origin_date).dt.days\n",
    "disasters['date'] = pd.to_datetime(disasters['daysSinceStart'], unit='D', origin=origin_date)\n",
    "\n",
    "# Create a unique index for each row\n",
    "disasters['index'] = disasters.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df4166-5f4c-410a-8bbc-ecfecb2191ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path to your shapefile\n",
    "county_shapefile_path = '../../../Local_Data/Geospatial/tl_2019_us_county.shp'\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(county_shapefile_path)\n",
    "\n",
    "# Ensure the GEOID column exists (modify if your column has a different name)\n",
    "if 'GEOID' not in gdf.columns:\n",
    "    raise ValueError(\"The GEOID column is not found in the shapefile.\")\n",
    "\n",
    "# Calculate centroids and extract coordinates to two decimal places\n",
    "gdf['centroid_lat'] = gdf.geometry.centroid.y.round(2)\n",
    "gdf['centroid_lon'] = gdf.geometry.centroid.x.round(2)\n",
    "\n",
    "# Create a DataFrame with GEOID, latitude, and longitude\n",
    "centroid_df = gdf[['GEOID', 'centroid_lat', 'centroid_lon']]\n",
    "\n",
    "# Ensure that 'fullFIPS' is properly formatted as a 5-character string\n",
    "centroid_df['GEOID'] = centroid_df['GEOID'].astype(int).astype(str)\n",
    "centroid_df['GEOID'] = centroid_df['GEOID'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = 'county_centroids.csv'\n",
    "centroid_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Centroid data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feaa76-5d9e-4558-9848-bcf9bf4ebdf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the latitude and longitude columns onto the disasters dataframe\n",
    "disasters = disasters.merge(\n",
    "    centroid_df[['GEOID', 'centroid_lat', 'centroid_lon']],\n",
    "    left_on='fullFIPS',\n",
    "    right_on='GEOID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the GEOID column if you don't need it\n",
    "disasters = disasters.drop(columns=['GEOID'])\n",
    "\n",
    "disaster_sensitivity(disasters, space_thres_list, time_thres_list, num_thres_list)\n",
    "# Save only the index and cluster columns\n",
    "disasters.to_csv(f\"{temp_folder}/clustered_disasters_sensitivity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd7f48-cd1b-49d3-9003-aa250751fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "disasters.to_csv(f\"{temp_folder}/clustered_disasters.csv\", index=False)\n",
    "\n",
    "print(\"Clustering complete. Output saved to 'clustered_disasters.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

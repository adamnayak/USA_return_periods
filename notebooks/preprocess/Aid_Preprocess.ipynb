{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf45612-e0ab-445b-8584-cfeeb4a10b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import time  # To track the elapsed time\n",
    "import matplotlib.colors as mcolors\n",
    "import concurrent.futures\n",
    "import re\n",
    "import string\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.patches as mpatches\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce07af14-8f87-4434-93e0-1f59b4f2885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize county names: lowercase and remove 'county', 'parish', and text in parentheses\n",
    "# Updated function to clean and standardize county names\n",
    "def clean_county_name(name):\n",
    "    # Convert to lowercase\n",
    "    name = name.lower()\n",
    "    # Remove 'county', 'parish', and any content within parentheses\n",
    "    name = re.sub(r'\\b(county|parish)\\b', '', name)\n",
    "    name = re.sub(r'\\(.*?\\)', '', name)\n",
    "    # Remove punctuation\n",
    "    name = name.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove extra whitespace\n",
    "    name = name.strip()\n",
    "    name = re.sub(r'\\s+', ' ', name)  # Replace multiple spaces with a single space\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a9e37-279e-4e28-a6cb-f3c2c360af18",
   "metadata": {},
   "source": [
    "# FIPS Code Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f783dbb-f15d-4921-b27b-7e61179d24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file line by line\n",
    "with open('../../../Local_Data/fips_codes.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Step 1: Identify where state-level data starts and ends\n",
    "state_section_start = 0\n",
    "county_section_start = 0\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if \"state-level\" in line.lower():\n",
    "        state_section_start = i + 2  # State data starts after the \"state-level\" heading\n",
    "    if \"county-level\" in line.lower():\n",
    "        county_section_start = i + 2  # County data starts after the \"county-level\" heading\n",
    "        break\n",
    "\n",
    "# Manually create the dictionary mapping state FIPS codes to state names\n",
    "state_fips_dict = {\n",
    "    \"01\": \"ALABAMA\",\n",
    "    \"02\": \"ALASKA\",\n",
    "    \"04\": \"ARIZONA\",\n",
    "    \"05\": \"ARKANSAS\",\n",
    "    \"06\": \"CALIFORNIA\",\n",
    "    \"08\": \"COLORADO\",\n",
    "    \"09\": \"CONNECTICUT\",\n",
    "    \"10\": \"DELAWARE\",\n",
    "    \"11\": \"DISTRICT OF COLUMBIA\",\n",
    "    \"12\": \"FLORIDA\",\n",
    "    \"13\": \"GEORGIA\",\n",
    "    \"15\": \"HAWAII\",\n",
    "    \"16\": \"IDAHO\",\n",
    "    \"17\": \"ILLINOIS\",\n",
    "    \"18\": \"INDIANA\",\n",
    "    \"19\": \"IOWA\",\n",
    "    \"20\": \"KANSAS\",\n",
    "    \"21\": \"KENTUCKY\",\n",
    "    \"22\": \"LOUISIANA\",\n",
    "    \"23\": \"MAINE\",\n",
    "    \"24\": \"MARYLAND\",\n",
    "    \"25\": \"MASSACHUSETTS\",\n",
    "    \"26\": \"MICHIGAN\",\n",
    "    \"27\": \"MINNESOTA\",\n",
    "    \"28\": \"MISSISSIPPI\",\n",
    "    \"29\": \"MISSOURI\",\n",
    "    \"30\": \"MONTANA\",\n",
    "    \"31\": \"NEBRASKA\",\n",
    "    \"32\": \"NEVADA\",\n",
    "    \"33\": \"NEW HAMPSHIRE\",\n",
    "    \"34\": \"NEW JERSEY\",\n",
    "    \"35\": \"NEW MEXICO\",\n",
    "    \"36\": \"NEW YORK\",\n",
    "    \"37\": \"NORTH CAROLINA\",\n",
    "    \"38\": \"NORTH DAKOTA\",\n",
    "    \"39\": \"OHIO\",\n",
    "    \"40\": \"OKLAHOMA\",\n",
    "    \"41\": \"OREGON\",\n",
    "    \"42\": \"PENNSYLVANIA\",\n",
    "    \"44\": \"RHODE ISLAND\",\n",
    "    \"45\": \"SOUTH CAROLINA\",\n",
    "    \"46\": \"SOUTH DAKOTA\",\n",
    "    \"47\": \"TENNESSEE\",\n",
    "    \"48\": \"TEXAS\",\n",
    "    \"49\": \"UTAH\",\n",
    "    \"50\": \"VERMONT\",\n",
    "    \"51\": \"VIRGINIA\",\n",
    "    \"53\": \"WASHINGTON\",\n",
    "    \"54\": \"WEST VIRGINIA\",\n",
    "    \"55\": \"WISCONSIN\",\n",
    "    \"56\": \"WYOMING\"\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easy merging\n",
    "state_df = pd.DataFrame(list(state_fips_dict.items()), columns=['State FIPS', 'State Name'])\n",
    "\n",
    "# Step 1: Split the data into sections\n",
    "state_section_start = 0\n",
    "county_section_start = 0\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if \"state-level\" in line.lower():\n",
    "        state_section_start = i + 2  # Skip the header lines\n",
    "    if \"county-level\" in line.lower():\n",
    "        county_section_start = i + 2  # Skip the header lines\n",
    "        break\n",
    "\n",
    "state_lines = lines[state_section_start:county_section_start-2]  # State data lines\n",
    "county_lines = lines[county_section_start:]  # County data line\n",
    "\n",
    "# Step 3: Parse county data\n",
    "county_fips = []\n",
    "county_name = []\n",
    "\n",
    "for line in county_lines:\n",
    "    line = line.strip()\n",
    "    if len(line) > 12 and line[:5].isdigit():\n",
    "        county_fips_code = line[:5].strip()\n",
    "        county_fips_name = line[12:].strip()\n",
    "        county_fips.append(county_fips_code)\n",
    "        county_name.append(county_fips_name)\n",
    "\n",
    "county_df = pd.DataFrame({\n",
    "    'countyCode': county_fips,\n",
    "    'County Name': county_name\n",
    "})\n",
    "\n",
    "county_df['State FIPS'] = county_df['countyCode'].str[:2]  # Extract state FIPS from the countyCode\n",
    "\n",
    "# Assuming county_df is already created and correctly populated:\n",
    "fips_df = county_df.merge(state_df, on='State FIPS')\n",
    "fips_df['County Name'] = fips_df['County Name'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683aa6a-e7d8-41f8-b93f-49adc6d450a5",
   "metadata": {},
   "source": [
    "# Load Aid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e392d5-708e-4672-acb0-450cf11c91b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3252/2566627724.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  HA_owners = pd.read_csv('../../../Local_Data/FEMA_Disaster_Asst_Data/HousingAssistanceOwners.csv')\n",
      "/tmp/ipykernel_3252/2566627724.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  HA_renters = pd.read_csv('../../../Local_Data/FEMA_Disaster_Asst_Data/HousingAssistanceRenters.csv')\n"
     ]
    }
   ],
   "source": [
    "HA_owners = pd.read_csv('../../../Local_Data/FEMA_Disaster_Asst_Data/HousingAssistanceOwners.csv')\n",
    "HA_renters = pd.read_csv('../../../Local_Data/FEMA_Disaster_Asst_Data/HousingAssistanceRenters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114ea4a7-8210-48ae-a2c1-90b5bfd8536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3252/261403972.py:54: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  matches = HA_renters_merged[HA_owners_merged['_merge'] == 'both']\n",
      "/tmp/ipykernel_3252/261403972.py:55: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  non_matches = HA_renters_merged[HA_owners_merged['_merge'] != 'both']\n"
     ]
    }
   ],
   "source": [
    "# Full mapping of state abbreviations to names\n",
    "state_abbr_to_name = {\n",
    "    \"AL\": \"ALABAMA\", \"AK\": \"ALASKA\", \"AZ\": \"ARIZONA\", \"AR\": \"ARKANSAS\", \"CA\": \"CALIFORNIA\",\n",
    "    \"CO\": \"COLORADO\", \"CT\": \"CONNECTICUT\", \"DE\": \"DELAWARE\", \"FL\": \"FLORIDA\", \"GA\": \"GEORGIA\",\n",
    "    \"HI\": \"HAWAII\", \"ID\": \"IDAHO\", \"IL\": \"ILLINOIS\", \"IN\": \"INDIANA\", \"IA\": \"IOWA\",\n",
    "    \"KS\": \"KANSAS\", \"KY\": \"KENTUCKY\", \"LA\": \"LOUISIANA\", \"ME\": \"MAINE\", \"MD\": \"MARYLAND\",\n",
    "    \"MA\": \"MASSACHUSETTS\", \"MI\": \"MICHIGAN\", \"MN\": \"MINNESOTA\", \"MS\": \"MISSISSIPPI\",\n",
    "    \"MO\": \"MISSOURI\", \"MT\": \"MONTANA\", \"NE\": \"NEBRASKA\", \"NV\": \"NEVADA\", \"NH\": \"NEW HAMPSHIRE\",\n",
    "    \"NJ\": \"NEW JERSEY\", \"NM\": \"NEW MEXICO\", \"NY\": \"NEW YORK\", \"NC\": \"NORTH CAROLINA\",\n",
    "    \"ND\": \"NORTH DAKOTA\", \"OH\": \"OHIO\", \"OK\": \"OKLAHOMA\", \"OR\": \"OREGON\", \"PA\": \"PENNSYLVANIA\",\n",
    "    \"RI\": \"RHODE ISLAND\", \"SC\": \"SOUTH CAROLINA\", \"SD\": \"SOUTH DAKOTA\", \"TN\": \"TENNESSEE\",\n",
    "    \"TX\": \"TEXAS\", \"UT\": \"UTAH\", \"VT\": \"VERMONT\", \"VA\": \"VIRGINIA\", \"WA\": \"WASHINGTON\",\n",
    "    \"WV\": \"WEST VIRGINIA\", \"WI\": \"WISCONSIN\", \"WY\": \"WYOMING\"\n",
    "}\n",
    "\n",
    "# Map state abbreviations to full names in HA_owners\n",
    "HA_owners['State Name'] = HA_owners['state'].map(state_abbr_to_name)\n",
    "HA_renters['State Name'] = HA_renters['state'].map(state_abbr_to_name)\n",
    "\n",
    "# Apply cleaning to county columns in both dataframes\n",
    "fips_df['County Name'] = fips_df['County Name'].apply(clean_county_name)\n",
    "HA_owners['county'] = HA_owners['county'].apply(clean_county_name)\n",
    "HA_renters['county'] = HA_renters['county'].apply(clean_county_name)\n",
    "\n",
    "\n",
    "# Merge on cleaned 'County Name' and 'State Name' to find matches\n",
    "HA_owners_merged = HA_owners.merge(fips_df[['County Name', 'State Name']], \n",
    "                            left_on=['county', 'State Name'], \n",
    "                            right_on=['County Name', 'State Name'], \n",
    "                            how='outer', \n",
    "                            indicator=True)\n",
    "HA_renters_merged = HA_renters.merge(fips_df[['County Name', 'State Name']], \n",
    "                            left_on=['county', 'State Name'], \n",
    "                            right_on=['County Name', 'State Name'], \n",
    "                            how='outer', \n",
    "                            indicator=True)\n",
    "\n",
    "# Define a set of valid US state abbreviations (50 states only)\n",
    "us_states = {\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\",\n",
    "    \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\",\n",
    "    \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "}\n",
    "\n",
    "# Get matching and non-matching pairs\n",
    "matches = HA_owners_merged[HA_owners_merged['_merge'] == 'both']\n",
    "non_matches = HA_owners_merged[HA_owners_merged['_merge'] != 'both']\n",
    "\n",
    "# Filter matching and non-matching pairs to include only those within the 50 states\n",
    "matching_pairs = {pair for pair in zip(matches['state'], matches['county']) if pair[0] in us_states}\n",
    "non_matching_pairs = {pair for pair in zip(non_matches['state'].dropna(), non_matches['county'].dropna()) if pair[0] in us_states}\n",
    "\n",
    "# Get matching and non-matching pairs\n",
    "matches = HA_renters_merged[HA_owners_merged['_merge'] == 'both']\n",
    "non_matches = HA_renters_merged[HA_owners_merged['_merge'] != 'both']\n",
    "\n",
    "# Filter matching and non-matching pairs to include only those within the 50 states\n",
    "matching_pairs = {pair for pair in zip(matches['state'], matches['county']) if pair[0] in us_states}\n",
    "non_matching_pairs = {pair for pair in zip(non_matches['state'].dropna(), non_matches['county'].dropna()) if pair[0] in us_states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bcbb264-59c3-4c3e-b85b-aa0ae5deb2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NA values in 'countyCode' after merging: 4.76%\n",
      "Percentage of NA values in 'countyCode' after merging: 5.06%\n"
     ]
    }
   ],
   "source": [
    "# Filter HA_owners to only include entries from the 50 U.S. states\n",
    "HA_owners_filtered = HA_owners[HA_owners['state'].isin(us_states)]\n",
    "\n",
    "# Filter HA_owners to only include entries from the 50 U.S. states\n",
    "HA_renters_filtered = HA_renters[HA_renters['state'].isin(us_states)]\n",
    "\n",
    "# Perform the merge to add 'countyCode' from fips_df to HA_owners\n",
    "HA_owners_with_code = HA_owners_filtered.merge(\n",
    "    fips_df[['countyCode', 'County Name', 'State Name']],\n",
    "    left_on=['county', 'State Name'],\n",
    "    right_on=['County Name', 'State Name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Perform the merge to add 'countyCode' from fips_df to HA_owners\n",
    "HA_renters_with_code = HA_renters_filtered.merge(\n",
    "    fips_df[['countyCode', 'County Name', 'State Name']],\n",
    "    left_on=['county', 'State Name'],\n",
    "    right_on=['County Name', 'State Name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the extra 'County Name' column that came from the merge\n",
    "HA_owners_with_code = HA_owners_with_code.drop(columns=['County Name'])\n",
    "\n",
    "# Drop the extra 'County Name' column that came from the merge\n",
    "HA_renters_with_code = HA_renters_with_code.drop(columns=['County Name'])\n",
    "\n",
    "# Calculate the percentage of NaN values in the 'countyCode' column\n",
    "na_percentage = HA_owners_with_code['countyCode'].isna().mean() * 100\n",
    "\n",
    "# Print the percentage of NaN values\n",
    "print(f\"Percentage of NA values in 'countyCode' after merging: {na_percentage:.2f}%\")\n",
    "\n",
    "# Calculate the percentage of NaN values in the 'countyCode' column\n",
    "na_percentage = HA_renters_with_code['countyCode'].isna().mean() * 100\n",
    "\n",
    "# Print the percentage of NaN values\n",
    "print(f\"Percentage of NA values in 'countyCode' after merging: {na_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "048a9774-c449-4ce4-8498-237c2d01868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out rows where 'countyCode' or 'disasterNumber' is NA\n",
    "owners_filtered_df = HA_owners_with_code.dropna(subset=['countyCode', 'disasterNumber'])\n",
    "\n",
    "# Aggregating the sum of 'approvedForFemaAssistance' by unique combinations of 'countyCode' and 'disasterNumber'\n",
    "owners_result_df = owners_filtered_df.groupby(['countyCode', 'disasterNumber'], as_index=False)[['approvedForFemaAssistance', 'totalApprovedIhpAmount']].sum()\n",
    "\n",
    "# Filtering out rows where 'countyCode' or 'disasterNumber' is NA\n",
    "renters_filtered_df = HA_renters_with_code.dropna(subset=['countyCode', 'disasterNumber'])\n",
    "\n",
    "# Aggregating the sum of 'approvedForFemaAssistance' by unique combinations of 'countyCode' and 'disasterNumber'\n",
    "renters_result_df = renters_filtered_df.groupby(['countyCode', 'disasterNumber'], as_index=False)[['approvedForFemaAssistance', 'totalApprovedIhpAmount']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd421ca5-8a83-4a3e-905f-0a6b800672c4",
   "metadata": {},
   "source": [
    "# Load Filtered Disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "495bcdb5-0987-44f3-93ad-f9d7d329ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters_df = pd.read_csv('../../final_filtered_disasters.csv')\n",
    "disasters_df['fullFIPS'] = disasters_df['fullFIPS'].astype(int).astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1031101-9d6a-4f75-bcbd-af6078f4452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owners Percentage of NA values in 'countyCode' after merging: 0.00%\n",
      "renters Percentage of NA values in 'countyCode' after merging: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Merging the result_df with disasters_df on 'countyCode' (from result_df) and 'fullFIPS' (from disasters_df),\n",
    "# and 'disasterNumber'\n",
    "owners_merged_df = disasters_df.merge(owners_result_df, left_on=['fullFIPS', 'disasterNumber'], \n",
    "                               right_on=['countyCode', 'disasterNumber'], how='left')\n",
    "\n",
    "# Dropping the duplicate 'countyCode' column after the merge as it duplicates 'fullFIPS'\n",
    "owners_merged_df = owners_merged_df.drop(columns=['countyCode'])\n",
    "\n",
    "# Merging the result_df with disasters_df on 'countyCode' (from result_df) and 'fullFIPS' (from disasters_df),\n",
    "# and 'disasterNumber'\n",
    "renters_merged_df = disasters_df.merge(renters_result_df, left_on=['fullFIPS', 'disasterNumber'], \n",
    "                               right_on=['countyCode', 'disasterNumber'], how='left')\n",
    "\n",
    "# Dropping the duplicate 'countyCode' column after the merge as it duplicates 'fullFIPS'\n",
    "renters_merged_df = renters_merged_df.drop(columns=['countyCode'])\n",
    "\n",
    "# Calculate the percentage of NaN values in the 'countyCode' column\n",
    "na_percentage = owners_merged_df['fullFIPS'].isna().mean() * 100\n",
    "\n",
    "# Print the percentage of NaN values\n",
    "print(f\"owners Percentage of NA values in 'countyCode' after merging: {na_percentage:.2f}%\")\n",
    "\n",
    "# Calculate the percentage of NaN values in the 'countyCode' column\n",
    "na_percentage = renters_merged_df['fullFIPS'].isna().mean() * 100\n",
    "\n",
    "# Print the percentage of NaN values\n",
    "print(f\"renters Percentage of NA values in 'countyCode' after merging: {na_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1d161-cc09-4a44-a3bc-b76d9aafa6d8",
   "metadata": {},
   "source": [
    "# Export Aid Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69dab51-c30e-4067-becb-43e41174fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "owners_merged_df.to_csv(\"final_filtered_aid_owners.csv\")\n",
    "renters_merged_df.to_csv(\"final_filtered_aid_renters.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
